---
title: 数据中心网络高可用架构
date: 2020-04-11 19:00:56
tags:
 - 数据中心
 - 高可用
 - 计算机网络
categories:
 - 路由交换技术
---
文章不错，转来
原文： http://www.h3c.com.cn/Solution/Operational/DataCenter/Solutions/201003/802841_30004_0.htm
转自： https://blog.csdn.net/xuyaqun/article/details/52487664


<div id="detailBody" style="color: rgb(127, 127, 127); --darkreader-inline-color:#bab5ab;" data-darkreader-inline-color="">

**相比传统的高可用技术，新技术的出现为构建数据中心网络的高可用架构提供了更优的部署方式。**

#### **一、 高可用性的定义**

传统意义上的可用性（AVAILABILITY ）定义为系统正常运行时间占总运行时间的比例（当前的总运行时间包括出问题以后修复所耗费的时间）。高可用性由两个基本概念组成：  
　　MTBF（Mean Time Between Failure），系统平均正常运行时间  
　　MTTR（Mean Time to Repair），系统平均恢复时间  
　　可用性的计算公式： AVAILABILITY ＝ MTBF / ( MTBF + MTTR ) × 100%

<div>

<div>

<div class="table-box">

<table border="1" cellspacing="0" cellpadding="0" width="445" align="center">

<tbody>

<tr>

<td valign="bottom" nowrap="nowrap">

可用性（每年）

</td>

<td valign="bottom" nowrap="nowrap">

故障时间（每年）

</td>

<td valign="bottom" nowrap="nowrap">

备注

</td>

</tr>

<tr>

<td valign="bottom" nowrap="nowrap">

98.000000%

</td>

<td valign="bottom" nowrap="nowrap">

7.3天

</td>

</tr>

<tr>

<td valign="bottom" nowrap="nowrap">

99.000000%

</td>

<td valign="bottom" nowrap="nowrap">

3.65天

</td>

</tr>

<tr>

<td valign="bottom" nowrap="nowrap">

99.900000%

</td>

<td valign="bottom" nowrap="nowrap">

8.76小时

</td>

</tr>

<tr>

<td valign="bottom" nowrap="nowrap">

99.990000%

</td>

<td valign="bottom" nowrap="nowrap">

52.56分钟

</td>

</tr>

<tr>

<td valign="bottom" nowrap="nowrap">

**99.999000%**

</td>

<td valign="bottom" nowrap="nowrap">

**5.256分钟**

</td>

<td valign="bottom" nowrap="nowrap">

**即"5个9的可用性"**

</td>

</tr>

<tr>

<td valign="bottom" nowrap="nowrap">

99.999900%

</td>

<td valign="bottom" nowrap="nowrap">

31.536秒

</td>

</tr>

<tr>

<td valign="bottom" nowrap="nowrap">

99.999990%

</td>

<td valign="bottom" nowrap="nowrap">

3.1537秒

</td>

</tr>

<tr>

<td valign="bottom" nowrap="nowrap">

99.999999%

</td>

<td valign="bottom" nowrap="nowrap">

0.31538秒

</td>

</tr>

</tbody>

</table>

</div>

</div>

</div>

<div>　　　　表1\. 以一年为时间段的不同等级的可用性与一年内的总故障时间的对应关系表</div>

网络节点与网络链路的故障无法完全避免，所以提升网络可用性的重要方法之一是尽量降低系统的故障恢复时间。

#### **二、 高可用技术**

应用于数据中心传统高可用技术主要包括：

物理设备：冗余电源、冗余风扇、冗余主控、板卡支持热插拔；

链路层面：以太网链路聚合（手工聚合、LACP）；

二层多路径：STP、MSTP、SmartLink；

三层多路径：VRRP、ECMP、动态路由协议多路径；

故障检测：NQA、BFD、OAM、DLDP；

不间断转发：GR、热补丁升级；

L4-L7多路径：状态热备、非对称路径转发；

在传统的数据中心三层网络结构中（如图1所示），由于存在多设备多路径冗余，就会存在环路结构，因此MSTP/VRRP/OSPF等处理多路径冗余的协议部署至关重要。一般在数据中心的核心到汇聚层间部署OSPF等动态路由协议，在汇聚层网关设备上部署VRRP处理多网关冗余，在汇聚层到接入层之间部署STP/MSTP解决二层网络环路冗余。当在汇聚层或核心层部署防火墙等基于4-7层的状态处理设备时，同时需要在多台设备间部署状态热备等特性。

为了保证数据中心的设备和链路发生故障时业务流量能够快速收敛，还需要部署NQA、BFD、OAM和DLDP等路径检测协议以降低故障检测响应时间。同时可以部署GR等不间断转发协议协助动态路由协议在主备板切换情况下快速完成业务流量收敛。

![](http://www.h3c.com.cn/res/201003/30/20100330_944632_image001_667976_30008_0.jpg)

图1 传统数据中心的高可用部署

新一代数据中心虚拟化网络架构中（如图2所示），通过IRF（Intelligent Resilient Framework）智能弹性架构技术将多台网络设备虚拟化成一台设备，并将这些设备看作单一设备进行管理和使用。这种"联合设备"被称为Fabric，组成Fabric的每台设备为一个Unit。IRF技术特性包含分布式设备管理（Distributed Device Management，DDM）、分布式弹性路由（Distributed Resilient Routing, DRR）和分布式链路聚合（Distributed Link Aggregation, DLA）功能。

DDM：用户可以将整个Fabric作为一台整体设备进行管理。通过连接到Fabric中任何一个端口、任何一个IP地址来管理整个Fabric，而不需要关心自己具体连接到了哪个Unit上。

DRR：Fabric的多个Unit在外界看来是一台单独的三层交换机。整个Fabric作为一台设备进行路由功能和报文转发功能，具有统一的VLAN接口、路由表和三层转发表。在某一个Unit发生故障时，路由协议和数据转发不受影响，从而减少业务中断。

DLA：用户可以将Fabric中不同Unit的多个端口进行聚合，实现对Fabric内统一的聚合管理。这不仅可以使聚合的设置更加方便，而且跨越设备的链路聚合也有效地避免了单点故障的发生。

![](http://www.h3c.com.cn/res/201003/30/20100330_944633_image002_667976_30008_0.jpg)

图2 IRF组网结构示意图

与传统的L2/L3网络设计相比，IRF技术构建的虚拟化网络架构主要有四个优点：

  **运营管理简化：**网络虚拟化能够提高运营效率，虚拟化的每一层交换机组被逻辑化为单管理点，包括配置文件和单一网关IP地址，无需VRRP。

  **整体无环设计：**跨设备的链路聚合DLA创建了简单的无环路拓扑结构，不再依靠生成树协议（STP/SMTP）或动态路由协议进行环路冗余路径处理。虚拟交换组内部经由标准万兆以太网接口相连，无需特殊电缆，在总体设计方面提供了灵活的部署能力。

  **进一步提高可用性：**虚拟化能够优化不间断通信，当其中一台虚拟交换机发生故障时，不再需要进行L2/L3重收敛，能快速实现业务通信流量的中断恢复。

  **增强的可扩展性：**与MSTP+VRRP设计收敛不同，通过虚拟化能在更短时间内完成确定性L2链路恢复，同时不影响L3链路。通过虚拟化能够实现网络各层的横向扩展，有利于服务器群的规模增大，设计更简单，完全不影响网络管理拓扑。各层之间通过增加捆绑链路单元即可平滑增加带宽，灵活性极强。

#### **三、 数据中心高可用架构**

**1. 服务器接入**

服务器接入的高可用设计也就是服务器多网卡接入。为了实现接入的高可用性，服务器通常采用多链路上行，即服务器采用两块或两块以上的网卡接入，服务器中的网络驱动程序和高可用集群软件可将两块或者多块网卡捆绑成一个虚拟的网卡，如果一个网卡失效，另一个网卡会接管它的MAC 地址，两块网卡使用同一个IP 地址，而且必须位于同一广播域，即同一子网下。

![](http://www.h3c.com.cn/res/201003/30/20100330_944634_image003_667976_30008_0.jpg)

图3 服务器和接入交换机之间的连接方式

服务器和接入交换机之间的连接方式（如图3所示），标号从1至4，拓扑的可用性依次降低。标号1采用接入层框式双机拓扑的网络可用性最高，标号2的框式多板卡冗余要比标号3的盒式多机冗余拓扑可用性更高，而标号4中单机盒式设备双网口冗余的网络可用性最低。因此推荐采用第1种接入方式，这种连接方式的服务器采用交换机容错模式分别接入到两台机柜式交换机上，并且将VLAN Trunk 到两台设备上，实现服务器的高可用接入。

**2. 接入层**

接入层到汇聚层共有4种连接方式，分别为倒U型接法、U型接法、三角形接法和矩形接法，这里所谓不同类型的接法是以二层链路作为评判依据，比如说矩形接法，从接入到接入，接入到汇聚、汇聚到汇聚均为二层链路连接，因此形成了矩形的二层链路接法。

![](http://www.h3c.com.cn/res/201003/30/20100330_944635_image004_667976_30008_0.jpg)

图4 接入层的高可用拓扑比较

<div>

<div>

<div class="table-box">

<table border="1" cellspacing="0" cellpadding="0" width="553" align="center">

<tbody>

<tr>

<td valign="bottom">

**拓扑**

</td>

<td valign="bottom">

**优点**

</td>

<td valign="bottom">

**缺点**

</td>

</tr>

<tr>

<td>

**1**

**倒U型**

</td>

<td>

不启用STP，好管理

VLAN 可以跨汇聚层交换机，服务器部署灵活

</td>

<td>

必须通过链路聚合保证高可用性

汇聚交换机故障时，服务器不可达，无法实现高可用接入

</td>

</tr>

<tr>

<td>

**2**

**U型**

</td>

<td>

不启用STP，好管理

双active链路，接入交换机密度高

</td>

<td>

不能使VLAN跨汇聚层，服务器部署不灵活

接入交换机间链路故障，VRRP心跳报文无法传递，整机做VRRP主备切换，故障收敛时间长。

</td>

</tr>

<tr>

<td>

**3**

**矩形**

</td>

<td>

双active链路，接入交换机密度高

VLAN可以跨汇聚层交换机

</td>

<td>

有一半的接入层流量要通过汇聚交换机之间的链路。当接入交换机上行链路故障时，所有流量将从一侧的交换机上行。收敛比变小，网络易拥塞，降低网络高可用性。

</td>

</tr>

<tr>

<td>

**4**

**三角形**

</td>

<td>

链路冗余，路径冗余，故障收敛时间最短

VLAN 可以跨汇聚层交换机，服务器部署灵活

</td>

<td>

接入交换机的密度小

</td>

</tr>

</tbody>

</table>

</div>

</div>

</div>

表2\. 四种拓扑连接方式的对比

由表2可以看出，三角形组网提供了更高的接入可用性以及更灵活的服务器扩展能力，所以常见推荐的组网采用第4种拓扑方式。

需要指出，接入交换机直接双上行与汇聚层设备相连，冗余连接并不是越多越好，而最小的三角形环能够提供最快的收敛速度和最高的可用性。例如图5中右侧图组网拓扑在接入层交换机和汇聚层交换机之间采用全交叉冗余，是一种过度冗余组网，反而增加交换机的生成树计算的复杂性以及故障排错的复杂性，所以不建议按这种方式部署。

![](http://www.h3c.com.cn/res/201003/30/20100330_944636_image005_667976_30008_0.jpg)

图5 接入层推荐组网方式

**3. 路由层面**

传统数据中心汇聚层到核心层间采用OSPF等动态路由协议进行路由层面高可用保障。常见连接方式一般分为以下2种（见图6）：

![](http://www.h3c.com.cn/res/201003/30/20100330_944637_image006_667976_30008_0.jpg)

图6 路由高可用拓扑比较

两种组网拓扑实际部署中可根据需求而定，第一种"倒三角"式组网适合对网络延迟较敏感，故障收敛速度要求较高的场景，缺点是网络的复杂度与维护难度较高；第二种"口字形"结构适用于冗余收敛要求较低场景，组网简单易于维护，缺点是故障收敛较慢。与接入层组网类似，这里不推荐使用全连接方式过度冗余，同样会导致组网设计的复杂度并增加排障难度。

**4. IRF高可用架构**

![](http://www.h3c.com.cn/res/201003/30/20100330_944638_image007_667976_30008_0.jpg)

图7 IRF架构与传统架构比较

传统架构服务器群网络拓扑与IRF架构服务器群网络拓扑相比（如图7所示），对于接入层而言，传统架构为保证网络高可用性通常采用服务器双网卡接入+MSTP+VRRP，服务器通过双网卡接入到两台交换机上，两台接入交换机采用双归属三角形拓扑接入到汇聚交换机，接入交换机与汇聚交换机之间需要运行MSTP协议，管理和维护比较复杂。但当接入交换机和汇聚交换机都采用IRF架构之后，可将每两台交换机（也可以是多台）配置成一个IRF堆叠组，两台汇聚交换机也配置成一个堆叠组，接入交换机与汇聚交换机之间通过捆绑链路连接。从逻辑上看，一个堆叠组就是一台设备，因此接入交换机和汇聚交换机间不存在二层环路，可以避免MSTP的配置管理，简化网络设计。

对于服务器的高可用接入方式，在IRF架构下，基本原则是服务器的双网卡接在不同交换机上，从而实现高可用性接入。

对于汇聚层交换机来说，设计方式与接入IRF是一致的，进行汇聚层交换机堆叠后，将两层交换机用多条链路进行捆绑连接，一般原则建议为偶数链路数，有利于将数据流量均衡到各链路。

图8给出了IRF二层接入设计下的HA考虑。基于虚拟化网络交换结构，服务器流量经过网络接入与汇聚层的路径十分清晰，简化为单条逻辑链路转发。对于情况B，当接入IRF架构的其中一台交换机出现故障，服务器网卡进行切换，通过另一台交换机即可恢复网络通信，而汇聚层设备无需任何变化，数据流仍从同一聚合链路进入网络。对情况C，汇聚层设备出现单台故障，服务器不感知，只由接入交换机将流量转发到聚合链路，汇聚层存活的交换机感知的仍是从现有聚合链路接收数据流。对于情况D，发生捆绑链路故障，交换机会将数据流转发到捆绑组存活链路上，对于IRF交换机组来说，数据流转的逻辑接口并未改变。

![](http://www.h3c.com.cn/res/201003/30/20100330_944639_image008_667976_30008_0.jpg)

图8 IRF接入层故障切换

IRF对外体现为一个整体交换系统，也存在由于意外原因导致IRF分裂的可能。RF分裂后，形成两个或多个相同的逻辑设备：地址相同、配置相同，需要进行检测和进一步处理以消除对网络的影响。

IRF系统作为逻辑单台设备，对外具有唯一的桥MAC（和三层MAC），IRF建立时，Master设备桥MAC同步到其它成员设备，分裂后，对于非Master所在系统，IRF中其它设备维持该桥MAC不变并选举新的Master，此机制可避免当原Master故障时网络中的邻居设备重新学习MAC。但IRF也有比较灵活的桥MAC处理方式以便于组网变通，目前一共提供了三种用户可以配置IRF系统MAC变化的方式：

  Master离开后，桥MAC立即变化

  保留6min变化

  始终不变

IRF系统分裂后，会在网络中形成两组或多组"完全相同"的设备组，均有相同配置的Active Master，IRF附加了检测和冲突处理，称为多Active检测（Multi-Active Detection，简称MAD）。

![](http://www.h3c.com.cn/res/201003/30/20100330_944640_image009_667976_30008_0.png)

图9 IRF分裂检测方式

检测：通过LACP（Link Aggregation Control Protocol，链路聚合控制协议）或者BFD（Bidirectional Forwarding Detection，双向转发检测）协议来检测网络中是否存在多个从同一个IRF系统分裂出去的全局配置相同的IRF（如图9所示）。

LACP方式下，H3C进行了扩展开发，在LACP协议报文中增加IRF Master ID ，当系统分裂后，分裂后的IRF系统有各自的Active Master ID，可通过LACP进行传递检测。

BFD方式下，也通过在BFD中扩展Master ID来检测冲突。

冲突处理：IRF分裂后，系统会检测到网络中存在多个处于Active状态相同的IRF。此时Master成员编号最小且处于Active状态的IRF系统会继续正常工作；Master成员编号较大且处于Active状态的IRF系统会迁移到Recovery状态，关闭该系统所有成员设备上除保留端口以外的其他全部物理端口。

故障恢复：IRF系统通过日志提示用户修复IRF互联链路，链路修复后，冲突的设备重新启动恢复IRF系统，被Down掉的端口将重新恢复业务转发。

#### **四、 结束语**

对数据中心而言，高可用性永远是必不可少的重要需求。数据中心的核心是业务数据，网络作为承载层需要保证运行于其上的数据的安全性与可用性，尤其是在网络节点链路发生故障情况下要确保业务可用与数据零丢失。从传统的环路冗余到现在的IRF堆叠，数据中心网络高可用技术将会不断优化进步，更好的满足高速发展的数据中心业务应用需求。

</div>

